{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1115394 characters\n"
     ]
    }
   ],
   "source": [
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print(f'Length of text: {len(text)} characters')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(vocab), mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([20, 53,  7, ..., 22, 29, 13], dtype=int64)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "all_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 50 # may be a hyperparam to optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=TensorSpec(shape=(51,), dtype=tf.int64, name=None)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = ids_dataset.batch(window_size+1, drop_remainder=True)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tes', 'est')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_df(sequence):\n",
    "    input_seq = sequence[:-1]\n",
    "    label_seq = sequence[1:]\n",
    "    return input_seq, label_seq\n",
    "create_df(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\root\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec=(TensorSpec(shape=(50,), dtype=tf.int64, name=None), TensorSpec(shape=(50,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = sequences.map(create_df)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : tf.Tensor(\n",
      "[20 53  7  2 32 59 36 53 32 53  8 55 61 17 13 65 55 30 46  7 55 59 42 55\n",
      " 59  5  7 46  6 55 55 35 59 40 61 60 59 30 15  7 32 18 55  7 31 59 18 55\n",
      " 40  7], shape=(50,), dtype=int64)\n",
      "Target: tf.Tensor(\n",
      "[53  7  2 32 59 36 53 32 53  8 55 61 17 13 65 55 30 46  7 55 59 42 55 59\n",
      "  5  7 46  6 55 55 35 59 40 61 60 59 30 15  7 32 18 55  7 31 59 18 55 40\n",
      "  7 59], shape=(50,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input :\", input_example)\n",
    "    print(\"Target:\", target_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 1000 # tf.data shuffles the data in a buffer instead of the memory so we have to give the buffer size (it does so cause\n",
    "# it could shuffle infinte size of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(64, 50), dtype=tf.int64, name=None), TensorSpec(shape=(64, 50), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = (dataset\n",
    "        .shuffle(BUFFER_SIZE)\n",
    "        .batch(BATCH_SIZE, drop_remainder=True)\n",
    "        .prefetch(tf.data.experimental.AUTOTUNE)# overlaps the training and the preprocessing when executing step s the pipeline prepares data for step s+1\n",
    "          )\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mySuperModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, dim_embedding, lstm_units):\n",
    "        super().__init__(self)\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, dim_embedding)\n",
    "        self.lstm = tf.keras.layers.LSTM(lstm_units,\n",
    "                                        return_sequences=True,\n",
    "                                        return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "    \n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = inputs\n",
    "        x = self.embedding(x,training=training)\n",
    "        \n",
    "        if states is None:\n",
    "            states = self.lstm.get_initial_state(x)\n",
    "        x, states, seq = self.lstm(x,initial_state=states, training=training)\n",
    "        x = self.dense(x, training=training)\n",
    "        \n",
    "        if  return_state:\n",
    "            return x, states\n",
    "        else:\n",
    "            return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "\n",
    "embedding = 256\n",
    "\n",
    "lstm_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = mySuperModel(vocab_size, embedding, lstm_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for input_seq, target in dataset.take(1):\n",
    "    prediction = my_model(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_super_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  16896     \n",
      "                                                                 \n",
      " lstm (LSTM)                 multiple                  5246976   \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  67650     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,331,522\n",
      "Trainable params: 5,331,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# why from_logits=True: https://datascience.stackexchange.com/\n",
    "#questions/73093/what-does-from-logits-true-do-in-sparsecategoricalcrossentropy-loss-function\n",
    "\n",
    "#https://stats.stackexchange.com/questions/326065/cross-entropy-vs-sparse-cross-entropy-when-to-use-one-over-the-other\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 50, 66)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         tf.Tensor(4.189948, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "example_batch_mean_loss = loss(target, prediction)\n",
    "print(\"Prediction shape: \", prediction.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True,\n",
    "    verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 2.4127\n",
      "Epoch 1: saving model to ./training_checkpoints\\ckpt_1\n",
      "341/341 [==============================] - 509s 1s/step - loss: 2.4127\n",
      "Epoch 2/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 1.7767\n",
      "Epoch 2: saving model to ./training_checkpoints\\ckpt_2\n",
      "341/341 [==============================] - 501s 1s/step - loss: 1.7767\n",
      "Epoch 3/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 1.5571\n",
      "Epoch 3: saving model to ./training_checkpoints\\ckpt_3\n",
      "341/341 [==============================] - 498s 1s/step - loss: 1.5571\n",
      "Epoch 4/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 1.4407\n",
      "Epoch 4: saving model to ./training_checkpoints\\ckpt_4\n",
      "341/341 [==============================] - 497s 1s/step - loss: 1.4407\n",
      "Epoch 5/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 1.3685\n",
      "Epoch 5: saving model to ./training_checkpoints\\ckpt_5\n",
      "341/341 [==============================] - 497s 1s/step - loss: 1.3685\n",
      "Epoch 6/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 1.3146\n",
      "Epoch 6: saving model to ./training_checkpoints\\ckpt_6\n",
      "341/341 [==============================] - 496s 1s/step - loss: 1.3146\n",
      "Epoch 7/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 1.2657\n",
      "Epoch 7: saving model to ./training_checkpoints\\ckpt_7\n",
      "341/341 [==============================] - 1198s 4s/step - loss: 1.2657\n",
      "Epoch 8/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 1.2186\n",
      "Epoch 8: saving model to ./training_checkpoints\\ckpt_8\n",
      "341/341 [==============================] - 497s 1s/step - loss: 1.2186\n",
      "Epoch 9/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 1.1684\n",
      "Epoch 9: saving model to ./training_checkpoints\\ckpt_9\n",
      "341/341 [==============================] - 497s 1s/step - loss: 1.1684\n",
      "Epoch 10/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 1.1156\n",
      "Epoch 10: saving model to ./training_checkpoints\\ckpt_10\n",
      "341/341 [==============================] - 498s 1s/step - loss: 1.1156\n",
      "Epoch 11/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 1.0589\n",
      "Epoch 11: saving model to ./training_checkpoints\\ckpt_11\n",
      "341/341 [==============================] - 497s 1s/step - loss: 1.0589\n",
      "Epoch 12/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.9994\n",
      "Epoch 12: saving model to ./training_checkpoints\\ckpt_12\n",
      "341/341 [==============================] - 497s 1s/step - loss: 0.9994\n",
      "Epoch 13/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.9404\n",
      "Epoch 13: saving model to ./training_checkpoints\\ckpt_13\n",
      "341/341 [==============================] - 496s 1s/step - loss: 0.9404\n",
      "Epoch 14/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.8817\n",
      "Epoch 14: saving model to ./training_checkpoints\\ckpt_14\n",
      "341/341 [==============================] - 497s 1s/step - loss: 0.8817\n",
      "Epoch 15/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.8286\n",
      "Epoch 15: saving model to ./training_checkpoints\\ckpt_15\n",
      "341/341 [==============================] - 497s 1s/step - loss: 0.8286\n",
      "Epoch 16/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.7784\n",
      "Epoch 16: saving model to ./training_checkpoints\\ckpt_16\n",
      "341/341 [==============================] - 495s 1s/step - loss: 0.7784\n",
      "Epoch 17/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.7365\n",
      "Epoch 17: saving model to ./training_checkpoints\\ckpt_17\n",
      "341/341 [==============================] - 499s 1s/step - loss: 0.7365\n",
      "Epoch 18/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.6991\n",
      "Epoch 18: saving model to ./training_checkpoints\\ckpt_18\n",
      "341/341 [==============================] - 495s 1s/step - loss: 0.6991\n",
      "Epoch 19/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.6662\n",
      "Epoch 19: saving model to ./training_checkpoints\\ckpt_19\n",
      "341/341 [==============================] - 497s 1s/step - loss: 0.6662\n",
      "Epoch 20/20\n",
      "341/341 [==============================] - ETA: 0s - loss: 0.6405\n",
      "Epoch 20: saving model to ./training_checkpoints\\ckpt_20\n",
      "341/341 [==============================] - 498s 1s/step - loss: 0.6405\n"
     ]
    }
   ],
   "source": [
    "history = my_model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: text_generator_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: text_generator_v1\\assets\n"
     ]
    }
   ],
   "source": [
    "my_model.save(\"text_generator_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = mySuperModel(vocab_size, embedding, lstm_units)\n",
    "my_model = tf.keras.models.load_model(\"text_generator_v1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[0]], dtype=int64)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_ids = ids_from_chars(['[UNK]'])[:, None]\n",
    "skip_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "    def __init__(self, model, chars_from_ids, ids_from_char):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = model\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.ids_from_chars = ids_from_char\n",
    "        \n",
    "        skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            # Put a -inf at each bad index.\n",
    "            values=[-float('inf')]*len(skip_ids),\n",
    "            indices=skip_ids,\n",
    "            # Match the shape to the vocabulary\n",
    "            dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "    @tf.function\n",
    "    def generate_the_next_step(self, inputs, states=None, run_eagerly=True):\n",
    "        \n",
    "        inputs_ids = self.ids_from_chars(tf.strings.unicode_split(inputs, 'UTF-8')).to_tensor()\n",
    "        print(inputs_ids.numpy())\n",
    "        predicted_logits, states = self.model(inputs_ids, states, return_state=True)\n",
    "        print(predicted_logits.shape)\n",
    "        predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "        #https://stackoverflow.com/questions/55063120/\n",
    "        #can-anyone-give-a-tiny-example-to-explain-the-params-of-tf-random-categorical\n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "        \n",
    "        predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "        \n",
    "        return predicted_chars, states\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(my_model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'ROMEO:'], shape=(1,), dtype=string)\n",
      "[[39 48 12  9 48 17]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"my_super_model\" \"                 f\"(type mySuperModel).\n\nCould not find matching concrete function to call loaded from the SavedModel. Got:\n  Positional arguments (4 total):\n    * <tf.Tensor 'inputs:0' shape=(1, 6) dtype=int64>\n    * None\n    * True\n    * False\n  Keyword arguments: {}\n\n Expected these arguments to match one of the following 4 option(s):\n\nOption 1:\n  Positional arguments (4 total):\n    * TensorSpec(shape=(None, 50), dtype=tf.int64, name='inputs')\n    * None\n    * False\n    * False\n  Keyword arguments: {}\n\nOption 2:\n  Positional arguments (4 total):\n    * TensorSpec(shape=(None, 50), dtype=tf.int64, name='inputs')\n    * None\n    * False\n    * True\n  Keyword arguments: {}\n\nOption 3:\n  Positional arguments (4 total):\n    * TensorSpec(shape=(None, 50), dtype=tf.int64, name='input_1')\n    * None\n    * False\n    * False\n  Keyword arguments: {}\n\nOption 4:\n  Positional arguments (4 total):\n    * TensorSpec(shape=(None, 50), dtype=tf.int64, name='input_1')\n    * None\n    * False\n    * True\n  Keyword arguments: {}\n\nCall arguments received by layer \"my_super_model\" \"                 f\"(type mySuperModel):\n  • args=('tf.Tensor(shape=(1, 6), dtype=int64)', 'None')\n  • kwargs={'return_state': 'True', 'training': 'False'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-9a211554b025>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_char\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mnext_char\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mone_step_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_the_next_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_char\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_char\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-0f0d1494ea4f>\u001b[0m in \u001b[0;36mgenerate_the_next_step\u001b[1;34m(self, inputs, states, run_eagerly)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0minputs_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mids_from_chars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0municode_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'UTF-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mpredicted_logits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_logits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mpredicted_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredicted_logits\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction_mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"my_super_model\" \"                 f\"(type mySuperModel).\n\nCould not find matching concrete function to call loaded from the SavedModel. Got:\n  Positional arguments (4 total):\n    * <tf.Tensor 'inputs:0' shape=(1, 6) dtype=int64>\n    * None\n    * True\n    * False\n  Keyword arguments: {}\n\n Expected these arguments to match one of the following 4 option(s):\n\nOption 1:\n  Positional arguments (4 total):\n    * TensorSpec(shape=(None, 50), dtype=tf.int64, name='inputs')\n    * None\n    * False\n    * False\n  Keyword arguments: {}\n\nOption 2:\n  Positional arguments (4 total):\n    * TensorSpec(shape=(None, 50), dtype=tf.int64, name='inputs')\n    * None\n    * False\n    * True\n  Keyword arguments: {}\n\nOption 3:\n  Positional arguments (4 total):\n    * TensorSpec(shape=(None, 50), dtype=tf.int64, name='input_1')\n    * None\n    * False\n    * False\n  Keyword arguments: {}\n\nOption 4:\n  Positional arguments (4 total):\n    * TensorSpec(shape=(None, 50), dtype=tf.int64, name='input_1')\n    * None\n    * False\n    * True\n  Keyword arguments: {}\n\nCall arguments received by layer \"my_super_model\" \"                 f\"(type mySuperModel):\n  • args=('tf.Tensor(shape=(1, 6), dtype=int64)', 'None')\n  • kwargs={'return_state': 'True', 'training': 'False'}"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['ROMEO:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "    print(next_char)\n",
    "    next_char, states = one_step_model.generate_the_next_step(next_char, states=states)\n",
    "    result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generer le tensor de la couche embedding pour voir l'entree de notre reseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tf-nightly 2.1.0.dev20191230\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
